{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow\n",
    "# ! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MfO30nSoUlsg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tensorflow.keras.datasets import imdb\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from torch.multiprocessing import Pool\n",
    "from keras.utils import to_categorical\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNTWEQ_MUlsi"
   },
   "source": [
    "# Import and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37zg2hZNUlsi",
    "outputId": "7bf71b0f-cd6b-413c-a07d-d917099f4b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> although i had seen <UNK> in a theater way back in <UNK> i couldn't remember anything of the plot except for vague images of kurt thomas running and fighting against a backdrop of stone walls and disappointment regarding the ending br br after reading some of the other reviews i picked up a copy of the newly released dvd to once again enter the world of <UNK> br br it turns out this is one of those films produced during the <UNK> that would go directly to video today the film stars <UNK> <UNK> kurt thomas as jonathan <UNK> <UNK> out of the blue to <UNK> the nation of <UNK> to enter and hopefully win the game a <UNK> <UNK> <UNK> by the khan who <UNK> his people by yelling what sounds like <UNK> power the goal of the mission involves the star wars defense system jonathan is trained in the martial arts by princess <UNK> who never speaks or leaves the house once trained tries to blend in with the <UNK> by wearing a bright red <UNK> with <UNK> of blue and white needless to say <UNK> finds himself running and fighting for his life along the stone streets of <UNK> on his way to a date with destiny and the game br br star kurt thomas was ill served by director robert <UNK> who it looks like was never on the set the so called script is just this side of incompetent see other reviews for the many <UNK> throughout the town of <UNK> has a few good moments but is ultimately ruined by bad editing the ending <UNK> still there's the <UNK> of a good action adventure here a hong kong version with more <UNK> action and faster pace might even be pretty good\n",
      "X shape: (100, 170)\n",
      "len(X[0]): 170\n",
      "len(X[1]): 170\n",
      "X[0]: [   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      "    2   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117    2   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56]\n"
     ]
    }
   ],
   "source": [
    "NUM_WORDS = 5000\n",
    "max_review_length = 100\n",
    "INDEX_FROM = 3\n",
    "\n",
    "# --- Import the IMDB data and only consider the ``top_words``` most used words\n",
    "np.load.__defaults__=(None, True, True, 'ASCII')\n",
    "(X, y), (X_test, y_test) = imdb.load_data(num_words=NUM_WORDS, index_from=INDEX_FROM)\n",
    "np.load.__defaults__=(None, False, True, 'ASCII')\n",
    "\n",
    "word_to_id = imdb.get_word_index()\n",
    "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
    "word_to_id[\"<PAD>\"] = 0\n",
    "word_to_id[\"<START>\"] = 1\n",
    "word_to_id[\"<UNK>\"] = 2\n",
    "\n",
    "id_to_word = {value:key for key,value in word_to_id.items()}\n",
    "print(' '.join(id_to_word[id] for id in X[1000] ))\n",
    "\n",
    "# --- filter sequences with at least 170 words\n",
    "TOTAL_LENGTH = 170\n",
    "X = [lst for lst in X if len(lst) >= TOTAL_LENGTH]\n",
    "# --- truncate input sequences\n",
    "X = sequence.pad_sequences(X, maxlen=TOTAL_LENGTH, truncating='post')\n",
    "# --- Keep only 100 sequences\n",
    "N = 100\n",
    "X = X[:N]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"len(X[0]):\", len(X[0]))\n",
    "print(\"len(X[1]):\", len(X[1]))\n",
    "print(\"X[0]:\", X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique_elements, counts = np.unique(X, return_counts=True)\n",
    "occurrences_dict = dict(zip(unique_elements, counts))\n",
    "\n",
    "keys = list(occurrences_dict.keys())[:500]\n",
    "values = list(occurrences_dict.values())[:500]\n",
    "\n",
    "plt.bar(keys, values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D4Y9Tr9dIClo",
    "outputId": "4450cdaf-6cfe-459a-f97b-133e96ece774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (100, 100)\n",
      "X_test shape: (100, 70)\n"
     ]
    }
   ],
   "source": [
    "# Train - test split\n",
    "LENGTH_TRAIN = 100\n",
    "X_train = X[:, :LENGTH_TRAIN]\n",
    "X_test = X[:, LENGTH_TRAIN:]\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty6AqZwAUlsj"
   },
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "23wnOVFHUlsj"
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, topics, model_length):\n",
    "        self.topics=topics\n",
    "        self.model_length=model_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.topics)-self.model_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input_sequence=torch.tensor(self.topics[index:index+self.model_length, :])\n",
    "        target_sequence=torch.tensor(self.topics[index+1:index+self.model_length+1, :])\n",
    "\n",
    "        return input_sequence, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Y7qp8RODUlsj"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, model_length, batch_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size #input size (NUM_TOPICS)\n",
    "        self.hidden_size = hidden_size #number of hidden neurons\n",
    "        self.output_size = output_size #output size (NUM_TOPICS)\n",
    "        self.model_length=model_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size, self.hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, x, prev_state):\n",
    "        output, state = self.lstm(x, prev_state)\n",
    "        output=self.fc(output)\n",
    "        probabilities = F.softmax(output[:, -1, :], dim=1)\n",
    "        return probabilities, state\n",
    "\n",
    "    def init_state(self):\n",
    "        return (torch.zeros(1, self.batch_size, self.hidden_size), #(NUM_LAYERS, BATCH SIZE, NUM_NEURONES)\n",
    "                torch.zeros(1, self.batch_size, self.hidden_size))\n",
    "\n",
    "    def train_model(self, dataset, optimizer, criterion):\n",
    "        state_h, state_c = self.init_state()\n",
    "        self.train()\n",
    "        for t, (x, y) in enumerate(dataset):\n",
    "            optimizer.zero_grad()\n",
    "            softmax , (state_h, state_c) = self(x, (state_h, state_c)) #softmax= p(z_{t+1}|z_1:t)\n",
    "            loss = criterion(softmax, y[:, -1, :])\n",
    "            state_h = state_h.detach()\n",
    "            state_c = state_c.detach()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    def predict_next_probability(self, input_sequence):\n",
    "        state_h, state_c = self.init_state()\n",
    "        with torch.no_grad():\n",
    "            for t in range(len(input_sequence)):\n",
    "                input_t = input_sequence[t].unsqueeze(0).unsqueeze(0)\n",
    "                _, (state_h, state_c) = self(input_t, (state_h, state_c))\n",
    "\n",
    "        input_t = input_sequence[-1].unsqueeze(0).unsqueeze(0)\n",
    "        probabilities, _ = self(input_t, (state_h, state_c))\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "    def sample_next_z(self, input_sequence):\n",
    "        proba = self.predict_next_probability(input_sequence)\n",
    "        return torch.multinomial(proba, 1).item()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kqrifMS5Ulsk"
   },
   "source": [
    "## SSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "DfZO1YK1Ulsk"
   },
   "outputs": [],
   "source": [
    "class SSMPytorch:\n",
    "    def __init__(self, num_words, num_topics):\n",
    "        self.num_words = num_words\n",
    "        self.num_topics = num_topics\n",
    "        self.phi = torch.randn(num_words, num_topics) * 0.01\n",
    "        self.phi = torch.exp(self.phi - torch.max(self.phi, dim=0, keepdim=True).values)\n",
    "        self.phi = self.phi / torch.sum(self.phi, dim=0, keepdim=True)\n",
    "\n",
    "    def compute_MLE_SSM(self, ech_x, ech_z):\n",
    "        n_samples = ech_x.shape[0]\n",
    "        proba_matrix = torch.zeros((self.num_words, self.num_topics), dtype=torch.float)\n",
    "        for i in range(n_samples):\n",
    "            index_x = ech_x[i] - 1\n",
    "            index_z = ech_z[i] - 1\n",
    "            proba_matrix[index_x, index_z] += 1.0\n",
    "        proba_matrix = proba_matrix + 1e-6\n",
    "        row_sums = proba_matrix.sum(dim=0, keepdim=True)\n",
    "        proba_matrix_normalized = proba_matrix / row_sums\n",
    "        self.phi = proba_matrix_normalized\n",
    "\n",
    "    def predict_proba(self, z_t):\n",
    "        return self.phi[:, int(z_t) - 1]\n",
    "\n",
    "    def sample_xt(self, z_t):\n",
    "        proba = self.predict_proba(z_t)\n",
    "        sampled_xt = torch.multinomial(proba, 1).item() + 1\n",
    "        return sampled_xt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33fdzrVuUlsl"
   },
   "source": [
    "## Particle Gibbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "RYDvZJPNUlsl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:16: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:25: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "def compute_alpha_unnormalized(z_1_t_minus_1, num_topics, num_voc, lstm, ssm):\n",
    "    z_1_t_minus_1 = z_1_t_minus_1 - 1\n",
    "    z_one_hot = F.one_hot(z_1_t_minus_1, num_classes=num_topics).float()\n",
    "    softmax = lstm.predict_next_probability(z_one_hot).detach()\n",
    "    phi = ssm.phi\n",
    "    alpha = torch.tensor([torch.matmul(softmax, phi[j, :]) for j in range(num_voc)])\n",
    "    return alpha\n",
    "\n",
    "def compute_alpha_normalized(z_1_t_minus_1, num_topics, num_voc, lstm, ssm):\n",
    "    num = compute_alpha_unnormalized(z_1_t_minus_1, num_topics, num_voc, lstm, ssm)\n",
    "    denom = torch.sum(num) + 1e-6\n",
    "    return num / denom\n",
    "\n",
    "def compute_gamma_unnormalized(xt, z_1_t_minus_1, num_topics, lstm, ssm):\n",
    "    z_1_t_minus_1 = z_1_t_minus_1 - 1\n",
    "    z_one_hot = F.one_hot(z_1_t_minus_1, num_classes=num_topics).float()\n",
    "    softmax = lstm.predict_next_probability(z_one_hot).detach()\n",
    "    phi = ssm.phi\n",
    "    phi_xt = phi[xt - 1, :]\n",
    "    return torch.mul(softmax, phi_xt)\n",
    "\n",
    "def compute_gamma_normalized(xt, z_1_t_minus_1, num_topics, lstm, ssm):\n",
    "    num = compute_gamma_unnormalized(xt, z_1_t_minus_1, num_topics, lstm, ssm)\n",
    "    denom = torch.sum(num) + 1e-6\n",
    "    return num / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "OldruShfhzBV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @jit\n"
     ]
    }
   ],
   "source": [
    "def particle_gibbs(x, previous_z_1_T_star, P, num_topics, num_words, T, lstm_model, ssm_model):\n",
    "    x = x.contiguous()\n",
    "    # Init\n",
    "    Z_matrix = torch.zeros((P, T + 1), dtype=torch.long)\n",
    "    alpha_matrix = torch.zeros((P, T + 1), dtype=torch.float)\n",
    "    ancestor_matrix = torch.ones((P, T + 1), dtype=torch.long)\n",
    "\n",
    "    # t=0\n",
    "    Z_matrix[:, 0] = torch.randint(1, num_topics + 1, (P,))\n",
    "    alpha_matrix[:, 0] = torch.full((P,), 1 / P)\n",
    "\n",
    "    # t=1\n",
    "    t = 1\n",
    "    ancestor_matrix[0, t - 1] = torch.tensor(1)\n",
    "    Z_matrix[0, 1:t + 1] = previous_z_1_T_star[:t]\n",
    "\n",
    "    for p in range(2, P + 1):\n",
    "        alpha_t_minus_1_p = alpha_matrix[:, t - 1]\n",
    "        a_t_minus_1_p = torch.multinomial(alpha_t_minus_1_p, 1).item()+1\n",
    "        ancestor_matrix[p - 1, t - 1] = a_t_minus_1_p\n",
    "        z_1_t_minus_1_a_t_minus_1_p = Z_matrix[int(a_t_minus_1_p) - 1, 0]\n",
    "        z_1_t_minus_1_a_t_minus_1_p = torch.tensor([z_1_t_minus_1_a_t_minus_1_p])\n",
    "        gamma_t_p = compute_gamma_normalized(xt=x[t - 1],\n",
    "                                             z_1_t_minus_1=z_1_t_minus_1_a_t_minus_1_p,\n",
    "                                             num_topics=num_topics,\n",
    "                                             lstm=lstm_model,\n",
    "                                             ssm=ssm_model)\n",
    "        Z_matrix[p - 1, 1:t + 1] = torch.multinomial(gamma_t_p, 1).item()+1\n",
    "\n",
    "    for p in range(1, P + 1):\n",
    "        a_t_minus_1_p = ancestor_matrix[p - 1, t - 1]\n",
    "        z_1_t_minus_1_a_t_minus_1_p = Z_matrix[int(a_t_minus_1_p) - 1, 0]\n",
    "        z_1_t_minus_1_a_t_minus_1_p = torch.tensor([z_1_t_minus_1_a_t_minus_1_p])\n",
    "        alpha_t_p = compute_alpha_normalized(z_1_t_minus_1=z_1_t_minus_1_a_t_minus_1_p,\n",
    "                                             num_topics=num_topics,\n",
    "                                             num_voc=num_words,\n",
    "                                             lstm=lstm_model,\n",
    "                                             ssm=ssm_model)\n",
    "        alpha_t_p = alpha_t_p[x[t - 1] - 1]\n",
    "        alpha_matrix[p - 1, t] = alpha_t_p\n",
    "\n",
    "    alpha_matrix[:, t] = alpha_matrix[:, t] / (alpha_matrix[:, t].sum() + 1e-6)\n",
    "\n",
    "    for t in range(2, T + 1):\n",
    "        a_t_minus_1 = torch.tensor(1)\n",
    "        z_1_t = previous_z_1_T_star[:t]\n",
    "        ancestor_matrix[0, t - 1] = a_t_minus_1\n",
    "        Z_matrix[0, 1:t + 1] = z_1_t\n",
    "\n",
    "        for p in range(2, P + 1):\n",
    "            alpha_t_minus_1_p = alpha_matrix[:, t - 1]\n",
    "            a_t_minus_1_p = torch.multinomial(alpha_t_minus_1_p, 1).item()+1\n",
    "            ancestor_matrix[p - 1, t - 1] = a_t_minus_1_p\n",
    "            z_1_t_minus_1_a_t_minus_1_p = Z_matrix[int(a_t_minus_1_p) - 1, 1:t]\n",
    "            gamma_t_p = compute_gamma_normalized(xt=x[t - 1],\n",
    "                                                 z_1_t_minus_1=z_1_t_minus_1_a_t_minus_1_p,\n",
    "                                                 num_topics=num_topics,\n",
    "                                                 lstm=lstm_model,\n",
    "                                                 ssm=ssm_model)\n",
    "\n",
    "            z_t_p = torch.multinomial(gamma_t_p, 1).item()+1\n",
    "            z_1_t_p = torch.cat([z_1_t_minus_1_a_t_minus_1_p, torch.tensor([z_t_p])])\n",
    "            Z_matrix[p - 1, 1:t + 1] = z_1_t_p\n",
    "\n",
    "        for p in range(1, P + 1):\n",
    "            a_t_minus_1_p = ancestor_matrix[p - 1, t - 1]\n",
    "            z_1_t_minus_1_a_t_minus_1_p = Z_matrix[int(a_t_minus_1_p) - 1, 1:(t - 1) + 1]\n",
    "            alpha_t_p = compute_alpha_normalized(z_1_t_minus_1=z_1_t_minus_1_a_t_minus_1_p,\n",
    "                                                 num_topics=num_topics,\n",
    "                                                 num_voc=num_words,\n",
    "                                                 lstm=lstm_model,\n",
    "                                                 ssm=ssm_model)\n",
    "            alpha_t_p = alpha_t_p[x[t - 1] - 1]\n",
    "            alpha_matrix[p - 1, t] = alpha_t_p\n",
    "\n",
    "        alpha_matrix[:, t] = alpha_matrix[:, t] / (alpha_matrix[:, t].sum() + 1e-6)\n",
    "\n",
    "    alpha_T = alpha_matrix[:, -1]\n",
    "    alpha_T = alpha_T / (alpha_T.sum() + 1e-6)\n",
    "    r = torch.multinomial(alpha_T, 1).item()+1\n",
    "    a_T_r = ancestor_matrix[int(r) - 1, -1]\n",
    "    z_1_T = Z_matrix[int(a_T_r) - 1, 1:]\n",
    "\n",
    "    return z_1_T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZVJyJMZTUlsl"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "X0AKORMeUlsl"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 64\n",
    "TRAIN_SEQUENCE_LENGTH = 100\n",
    "TEST_SEQUENCE_LENGTH = 70\n",
    "MODEL_LENGTH = 10\n",
    "NUM_TOPICS = 50\n",
    "NUM_WORDS = 5000\n",
    "N_EPOCHS = 20\n",
    "NUM_PARTICULES = 10\n",
    "\n",
    "lstm_model=LSTM(input_size=NUM_TOPICS, hidden_size=HIDDEN_SIZE, output_size=NUM_TOPICS, model_length=MODEL_LENGTH, batch_size=1)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(lstm_model.parameters(), lr=0.001)\n",
    "ssm_model = SSMPytorch(num_words=NUM_WORDS, num_topics=NUM_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08ig8h2-Uwbe",
    "outputId": "a198bd0d-7866-4648-db49-c2e4138050b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"particle_gibbs\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py (1)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"particle_gibbs\" failed type inference due to: \u001b[1m\u001b[1mCannot determine Numba type of <class 'numba.core.dispatcher.LiftedLoop'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"particle_gibbs\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"particle_gibbs\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py (18)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"particle_gibbs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 18:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:25: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"compute_gamma_normalized\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py (25)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 25:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"compute_gamma_normalized\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 25:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 25:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:16: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"compute_gamma_unnormalized\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py (16)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 16:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"compute_gamma_unnormalized\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 16:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 16:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"particle_gibbs\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py (31)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 31:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"particle_gibbs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 31:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 31:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:10: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"compute_alpha_normalized\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py (10)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 10:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"compute_alpha_normalized\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 10:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 10:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"compute_alpha_unnormalized\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py (1)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"compute_alpha_unnormalized\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\1843237727.py\", line 1:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"particle_gibbs\" failed type inference due to: \u001b[1m\u001b[1mnon-precise type pyobject\u001b[0m\n",
      "\u001b[0m\u001b[1mDuring: typing of argument at C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py (43)\u001b[0m\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 43:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:151: NumbaWarning: \u001b[1mFunction \"particle_gibbs\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 43:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaWarning(warn_msg,\n",
      "c:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\numba\\core\\object_mode_passes.py:161: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected. This is deprecated behaviour that will be removed in Numba 0.59.0.\n",
      "\n",
      "For more information visit https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"..\\..\\..\\..\\..\\AppData\\Local\\Temp\\ipykernel_167724\\3894141534.py\", line 43:\u001b[0m\n",
      "\u001b[1m<source missing, REPL/exec in use?>\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg,\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\2488810157.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_sequence=torch.tensor(self.topics[index:index+self.model_length, :])\n",
      "C:\\Users\\yanis\\AppData\\Local\\Temp\\ipykernel_167724\\2488810157.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target_sequence=torch.tensor(self.topics[index+1:index+self.model_length+1, :])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     12\u001b[0m     X_train_torch_i \u001b[38;5;241m=\u001b[39m X_train_torch[i]\n\u001b[1;32m---> 13\u001b[0m     z_star_train_i \u001b[38;5;241m=\u001b[39m particle_gibbs(X_train_torch_i, previous_z_1_T_star[i], NUM_PARTICULES, NUM_TOPICS, NUM_WORDS, TRAIN_SEQUENCE_LENGTH, lstm_model, ssm_model)\n\u001b[0;32m     14\u001b[0m     z_star_one_hot_train_i \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(z_star_train_i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39mNUM_TOPICS)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m     15\u001b[0m     dataset_i\u001b[38;5;241m=\u001b[39mDataset(topics\u001b[38;5;241m=\u001b[39mz_star_one_hot_train_i, model_length\u001b[38;5;241m=\u001b[39mMODEL_LENGTH)\n",
      "Cell \u001b[1;32mIn[19], line 41\u001b[0m, in \u001b[0;36mLSTM.predict_next_probability\u001b[1;34m(self, input_sequence)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(input_sequence)):\n\u001b[0;32m     40\u001b[0m         input_t \u001b[38;5;241m=\u001b[39m input_sequence[t]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m         _, (state_h, state_c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(input_t, (state_h, state_c))\n\u001b[0;32m     43\u001b[0m input_t \u001b[38;5;241m=\u001b[39m input_sequence[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     44\u001b[0m probabilities, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(input_t, (state_h, state_c))\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[19], line 16\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, x, prev_state)\u001b[0m\n\u001b[0;32m     14\u001b[0m output, state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, prev_state)\n\u001b[0;32m     15\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(output)\n\u001b[1;32m---> 16\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(output[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probabilities, state\n",
      "File \u001b[1;32mc:\\Users\\yanis\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:1856\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1854\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1856\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1858\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_torch = torch.tensor(X_train, dtype = torch.long)\n",
    "X_test_torch = torch.tensor(X_test, dtype = torch.long)\n",
    "\n",
    "list_mean_loss = []\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    print(\"epoch: {}\".format(epoch+1))\n",
    "    previous_z_1_T_star = torch.randint(1, NUM_TOPICS + 1, (X_train_torch.shape[0], TRAIN_SEQUENCE_LENGTH))\n",
    "    z_star_train = []\n",
    "    for i in range(X_train.shape[0]):\n",
    "        X_train_torch_i = X_train_torch[i]\n",
    "        z_star_train_i = particle_gibbs(X_train_torch_i, previous_z_1_T_star[i], NUM_PARTICULES, NUM_TOPICS, NUM_WORDS, TRAIN_SEQUENCE_LENGTH, lstm_model, ssm_model)\n",
    "        z_star_one_hot_train_i = F.one_hot(z_star_train_i-1, num_classes=NUM_TOPICS).float()\n",
    "        dataset_i=Dataset(topics=z_star_one_hot_train_i, model_length=MODEL_LENGTH)\n",
    "        dataloader_i = DataLoader(dataset_i, batch_size=1)\n",
    "        lstm_model.train_model(dataloader_i, optimizer, criterion)\n",
    "        ssm_model.compute_MLE_SSM(X_train_torch_i, z_star_train_i)\n",
    "        z_star_train.append(z_star_train_i)\n",
    "    \n",
    "    z_star_train = torch.stack(z_star_train)\n",
    "    \n",
    "    z_pred = []\n",
    "    for i in range(z_star_train.shape[0]):\n",
    "        input_sequence = z_star_train[i]\n",
    "        input_seq_one_hot = F.one_hot(input_sequence-1, num_classes=NUM_TOPICS).float()\n",
    "        input_seq_one_hot = input_seq_one_hot\n",
    "        for t in range(TEST_SEQUENCE_LENGTH):\n",
    "            z_next = torch.tensor([lstm_model.sample_next_z(input_seq_one_hot)])\n",
    "            input_sequence = torch.cat([input_sequence, z_next])\n",
    "            input_seq_one_hot = F.one_hot(input_sequence-1, num_classes=NUM_TOPICS).float()\n",
    "        z_pred_i = input_sequence[-TEST_SEQUENCE_LENGTH:]\n",
    "        z_pred.append(z_pred_i)\n",
    "    z_pred = torch.stack(z_pred)\n",
    "    \n",
    "    loss = 0\n",
    "    for i in range(z_pred.shape[0]):\n",
    "        z_pred_i = z_pred[i]\n",
    "        proba_x_pred_i = []\n",
    "        for t in range(TEST_SEQUENCE_LENGTH):\n",
    "            z_pred_i_t = z_pred_i[t].item()\n",
    "            proba_x_pred_i_t = ssm_model.predict_proba(z_pred_i_t)\n",
    "            proba_x_pred_i.append(proba_x_pred_i_t)\n",
    "        proba_x_pred_i = torch.stack(proba_x_pred_i)\n",
    "        X_test_i = X_test_torch[i]\n",
    "        cross_entropy = F.cross_entropy(proba_x_pred_i, X_test_i)\n",
    "        perplexity  = torch.exp(cross_entropy)\n",
    "        loss += perplexity\n",
    "    mean_loss = loss/z_pred.shape[0]\n",
    "    mean_loss_item = mean_loss.item()\n",
    "    print(\"Perplexity: {}\".format(mean_loss_item))\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Elapsed Time: {:.2f} seconds\".format(elapsed_time))\n",
    "    list_mean_loss.append(mean_loss_item)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
